{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functions.helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKkJWkb9juKa",
        "outputId": "3c23db72-6af4-4882-c703-80db6801ca91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYBFSCiJrvsG"
      },
      "source": [
        "#Import Lib and Def Func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YqHgPPftZO8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support, \\\n",
        "    confusion_matrix\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split ,KFold\n",
        "import pickle\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier ,GradientBoostingClassifier ,AdaBoostClassifier ,ExtraTreesClassifier ,VotingClassifier ,StackingClassifier\n",
        " \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        " \n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtWebXNbUF5A",
        "outputId": "786962db-bc4d-4710-f59d-c347187e2ffe"
      },
      "outputs": [],
      "source": [
        "## load all data set in to a dataframe dictionary (UPDATE :NORMALIZED)\n",
        "\n",
        "all_df=get_all_df_dict(normalize=False ,normalize_feature_list=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMpIpc-TPpet",
        "outputId": "20244abd-24aa-434a-8bc3-4e376c610f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary\n",
            " Class 0- True news \n",
            " Class 1 - False news\n",
            "\n",
            "prec-t\tprec-f\trec-t\trec-f\tf1-t\tf1-f\taccu\ttn\tfp\tfn\ttp\tdataset\tmodel\n",
            "0.633\t0.781\t0.892\t0.428\t0.740\t0.553\t0.672\t1990\t242\t1154\t864\tcodalab\tGaussian Naive Bayes\n",
            "0.770\t0.458\t0.955\t0.117\t0.853\t0.186\t0.751\t4705\t220\t1404\t186\tfakenewsnet\tGaussian Naive Bayes\n",
            "0.999\t0.998\t0.998\t0.999\t0.999\t0.999\t0.999\t6414\t11\t5\t6812\tisot\tGaussian Naive Bayes\n",
            "0.972\t0.987\t0.987\t0.971\t0.980\t0.979\t0.979\t940\t12\t27\t910\tkagglerealfake\tGaussian Naive Bayes\n",
            "0.564\t0.569\t0.875\t0.196\t0.686\t0.291\t0.565\t1206\t172\t933\t227\tliar\tGaussian Naive Bayes\n"
          ]
        }
      ],
      "source": [
        "# Train using all the features \n",
        "print(\"Summary\\n Class 0- True news \\n Class 1 - False news\\n\")\n",
        "print(\"{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format('prec-t','prec-f', 'rec-t','rec-f','f1-t','f1-f','accu','tn', 'fp', 'fn', 'tp',\"dataset\",\"model\"))  # correct\n",
        "\n",
        "\n",
        "classifiers=[\n",
        "          #  ['Logistic Regression',LogisticRegression()],\n",
        "    #  ['Decision Tree Classification',DecisionTreeClassifier()],\n",
        "    #  ['Gradient Boosting Classification', GradientBoostingClassifier()],\n",
        "    #  ['Ada Boosting Classification',AdaBoostClassifier()],\n",
        "    #  ['Extra Tree Classification', ExtraTreesClassifier(n_estimators=300)],\n",
        "    #  ['K-Neighbors Classification',KNeighborsClassifier()],\n",
        "    #  ['Support Vector Classification',SVC()],\n",
        "      ['Gaussian Naive Bayes',GaussianNB()],\n",
        "    #  [\"xgBoost\",xgb.XGBClassifier()]\n",
        "]\n",
        "\n",
        "for key,value in all_df.items(): #for each dataset in all_df\n",
        "  # print(\"----------\",key,\"--------------\")\n",
        "  df = value\n",
        "  if (key==\"codalab\" or key==\"liar\"):\n",
        "    df_train = df.loc[df[\"split_Sementic\"]==\"train\"][All_features+['label']]\n",
        "    df_test = df.loc[df[\"split_Sementic\"]!=\"train\"][All_features+['label']]  \n",
        "\n",
        "    X_train=df_train[All_features]\n",
        "    y_train=df_train[\"label\"]\n",
        "    X_val=df_test[All_features]\n",
        "    y_val=df_test[\"label\"]\n",
        "  else:\n",
        "    X_train, X_val, y_train, y_val = train_test_split(df[All_features], df[\"label\"], test_size=0.3, random_state=142,stratify=df[\"label\"])\n",
        "  \n",
        "\n",
        "  compare_models( X_train, X_val, y_train, y_val ,All_features,key ,classifiers,) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfn-7ntDULQk",
        "outputId": "00f5ea2b-eb3c-46fc-93fd-afff7057e78f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prec-t\tprec-f\trec-t\trec-f\tf1-t\tf1-f\taccu\ttn\tfp\tfn\ttp\tdataset\tmodel\n",
            "0.637\t0.801\t0.904\t0.428\t0.747\t0.558\t0.678\t5048\t535\t2880\t2157\tcodalab\t\t\tcodalab\n",
            "0.360\t0.342\t0.304\t0.400\t0.330\t0.369\t0.350\t1700\t3883\t3021\t2016\tcodalab\t\t\tfakenewsnet\n",
            "0.256\t0.472\t0.004\t0.987\t0.008\t0.639\t0.470\t22\t5561\t64\t4973\tcodalab\t\t\tisot\n",
            "0.278\t0.442\t0.061\t0.826\t0.099\t0.576\t0.424\t338\t5245\t876\t4161\tcodalab\t\t\tkagglerealfake\n",
            "0.598\t0.566\t0.637\t0.526\t0.617\t0.546\t0.584\t3554\t2029\t2386\t2651\tcodalab\t\t\tliar\n",
            "0.792\t0.304\t0.652\t0.470\t0.715\t0.369\t0.607\t10694\t5720\t2807\t2494\tfakenewsnet\t\t\tcodalab\n",
            "0.772\t0.504\t0.961\t0.124\t0.856\t0.198\t0.756\t15769\t645\t4646\t655\tfakenewsnet\t\t\tfakenewsnet\n",
            "0.851\t0.244\t0.003\t0.998\t0.007\t0.393\t0.246\t57\t16357\t10\t5291\tfakenewsnet\t\t\tisot\n",
            "0.788\t0.246\t0.071\t0.941\t0.130\t0.391\t0.283\t1159\t15255\t312\t4989\tfakenewsnet\t\t\tkagglerealfake\n",
            "0.812\t0.291\t0.487\t0.651\t0.609\t0.402\t0.527\t7995\t8419\t1850\t3451\tfakenewsnet\t\t\tliar\n",
            "0.575\t0.870\t0.946\t0.340\t0.715\t0.489\t0.634\t20265\t1151\t15002\t7722\tisot\t\t\tcodalab\n",
            "0.799\t0.936\t0.943\t0.776\t0.865\t0.849\t0.857\t20200\t1216\t5081\t17643\tisot\t\t\tfakenewsnet\n",
            "0.999\t0.998\t0.998\t0.999\t0.999\t0.999\t0.999\t21376\t40\t18\t22706\tisot\t\t\tisot\n",
            "0.995\t0.999\t0.999\t0.995\t0.997\t0.997\t0.997\t21394\t22\t103\t22621\tisot\t\t\tkagglerealfake\n",
            "0.622\t0.734\t0.790\t0.547\t0.696\t0.627\t0.665\t16917\t4499\t10302\t12422\tisot\t\t\tliar\n",
            "0.536\t0.695\t0.915\t0.196\t0.676\t0.306\t0.558\t2902\t269\t2510\t613\tkagglerealfake\t\t\tcodalab\n",
            "0.622\t0.659\t0.714\t0.560\t0.665\t0.605\t0.638\t2264\t907\t1374\t1749\tkagglerealfake\t\t\tfakenewsnet\n",
            "0.999\t0.833\t0.803\t0.999\t0.891\t0.909\t0.901\t2547\t624\t2\t3121\tkagglerealfake\t\t\tisot\n",
            "0.965\t0.986\t0.987\t0.964\t0.976\t0.975\t0.975\t3129\t42\t113\t3010\tkagglerealfake\t\t\tkagglerealfake\n",
            "0.560\t0.728\t0.894\t0.288\t0.689\t0.412\t0.593\t2835\t336\t2225\t898\tkagglerealfake\t\t\tliar\n",
            "0.568\t0.478\t0.812\t0.218\t0.668\t0.299\t0.550\t5765\t1335\t4386\t1223\tliar\t\t\tcodalab\n",
            "0.560\t0.611\t0.996\t0.008\t0.717\t0.015\t0.560\t7072\t28\t5565\t44\tliar\t\t\tfakenewsnet\n",
            "0.578\t0.444\t0.141\t0.869\t0.227\t0.588\t0.463\t1003\t6097\t733\t4876\tliar\t\t\tisot\n",
            "0.571\t0.475\t0.752\t0.284\t0.649\t0.356\t0.545\t5338\t1762\t4015\t1594\tliar\t\t\tkagglerealfake\n",
            "0.576\t0.540\t0.876\t0.184\t0.695\t0.274\t0.571\t6223\t877\t4579\t1030\tliar\t\t\tliar\n"
          ]
        }
      ],
      "source": [
        "# load models \n",
        "models={}\n",
        "baseModelPath= outputDirectory\n",
        "predictionScore= []\n",
        "\n",
        "# trained_models_path={\n",
        "#   \"codalab\":baseModelPath+\"codalab\"+\"_Extra Tree Classification.pkl\",\n",
        "#   \"fakenewsnet\": baseModelPath+\"fakenewsnet\"+\"_Extra Tree Classification.pkl\",\n",
        "#   \"isot\": baseModelPath+\"isot\"+\"_Extra Tree Classification.pkl\",\n",
        "#   \"kagglerealfake\": baseModelPath+\"kagglerealfake\"+\"_Extra Tree Classification.pkl\",\n",
        "#   \"liar\":baseModelPath+\"liar\"+\"_Extra Tree Classification.pkl\",\n",
        "# }\n",
        "\n",
        "trained_models_path={\n",
        "  \"codalab\":baseModelPath+\"codalab\"+\"_Gaussian Naive Bayes.pkl\",\n",
        "  \"fakenewsnet\": baseModelPath+\"fakenewsnet\"+\"_Gaussian Naive Bayes.pkl\",\n",
        "  \"isot\": baseModelPath+\"isot\"+\"_Gaussian Naive Bayes.pkl\",\n",
        "  \"kagglerealfake\": baseModelPath+\"kagglerealfake\"+\"_Gaussian Naive Bayes.pkl\",\n",
        "  \"liar\":baseModelPath+\"liar\"+\"_Gaussian Naive Bayes.pkl\",\n",
        "}\n",
        " \n",
        "\n",
        "print(\"{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format('prec-t','prec-f', 'rec-t','rec-f','f1-t','f1-f','accu','tn', 'fp', 'fn', 'tp',\"dataset\",\"model\"))  # correct\n",
        "\n",
        "\n",
        "# need to load the model one at a time to avoid crash \n",
        "for key1,value1 in all_df.items():\n",
        "  df = value1\n",
        "  X_val=df[All_features]\n",
        "  y_val=df[\"label\"]\n",
        "  for key2,value in trained_models_path.items(): \n",
        "    Path =value\n",
        "    value2=read_pickle_model(Path)\n",
        "    predict_for_model(X_val,y_val,All_features,key1,value2,key2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZTlDjHL2B3u"
      },
      "source": [
        "# Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCwSrtgmBlQD",
        "outputId": "95cf25f4-5037-4f97-b073-2a105f0d7209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary\n",
            " Class 0- True news \n",
            " Class 1 - False news\n",
            "\n",
            "prec-t\tprec-f\trec-t\trec-f\tf1-t\tf1-f\taccu\ttn\tfp\tfn\ttp\tdataset\tmodel\n",
            "0.612\t0.802\t0.921\t0.354\t0.735\t0.491\t0.652\t2055\t177\t1303\t715\tcodalab\tExtraTreesoft\n",
            "0.763\t0.514\t0.983\t0.056\t0.859\t0.101\t0.757\t4841\t84\t1501\t89\tfakenewsnet\tExtraTreesoft\n",
            "0.828\t0.985\t0.987\t0.806\t0.900\t0.887\t0.894\t6340\t85\t1321\t5496\tisot\tExtraTreesoft\n",
            "0.721\t0.979\t0.987\t0.612\t0.833\t0.753\t0.801\t940\t12\t364\t573\tkagglerealfake\tExtraTreesoft\n",
            "0.557\t0.588\t0.929\t0.121\t0.696\t0.200\t0.559\t1280\t98\t1020\t140\tliar\tExtraTreesoft\n"
          ]
        }
      ],
      "source": [
        "# Train using all the features | Voting claasifier \n",
        "n_estimators=300\n",
        "voting=\"soft\"\n",
        "print(\"Summary\\n Class 0- True news \\n Class 1 - False news\\n\")\n",
        "print(\"{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format('prec-t','prec-f', 'rec-t','rec-f','f1-t','f1-f','accu','tn', 'fp', 'fn', 'tp',\"dataset\",\"model\"))  # correct\n",
        "\n",
        "for key,value in all_df.items():\n",
        "  # print(\"----------\",key,\"--------------\")\n",
        "  df = value\n",
        "  if (key==\"codalab\" or key==\"liar\"):\n",
        "    df_train = df.loc[df[\"split_Sementic\"]==\"train\"][All_features+['label']]\n",
        "    df_test = df.loc[df[\"split_Sementic\"]!=\"train\"][All_features+['label']]  \n",
        "\n",
        "    X_train=df_train[All_features]\n",
        "    y_train=df_train[\"label\"]\n",
        "    X_val=df_test[All_features]\n",
        "    y_val=df_test[\"label\"]\n",
        "  else:\n",
        "    X_train, X_val, y_train, y_val = train_test_split(df[All_features], df[\"label\"], test_size=0.3, random_state=142,stratify=df[\"label\"])\n",
        "  \n",
        "\n",
        "  # column transforemers \n",
        "  sementic_ct = ColumnTransformer([(\"sementic\",\"passthrough\", Sementic_features )])\n",
        "  lex_ct_embed_ct = ColumnTransformer([(\"lexicon\",\"passthrough\", LexMod_Features +Embed_features)])\n",
        "  Emotion_ct = ColumnTransformer([(\"emotion\",\"passthrough\", Emotion_features )])\n",
        "  # embed_ct = ColumnTransformer([(\"embedding\",\"passthrough\", embed_features )])\n",
        "\n",
        "  \n",
        "  GaussianNB\n",
        "  # def model for each estimators\n",
        "  model_sementic_clf = GaussianNB() #  ExtraTreesClassifier(n_estimators=n_estimators)\n",
        "  model_lex_emd_clf =  GaussianNB() # ExtraTreesClassifier(n_estimators=n_estimators)\n",
        "  model_emotion_clf =  GaussianNB() #ExtraTreesClassifier(n_estimators=n_estimators)\n",
        "  # model_embd_pipeline = ExtraTreesClassifier()\n",
        "  # final_estimator=ExtraTreesClassifier()\n",
        "\n",
        "\n",
        "# create pipeline \n",
        "  sementic_pipeline = Pipeline([\n",
        "        ('trans', sementic_ct),\n",
        "        ('clf', model_sementic_clf)\n",
        "        ]\n",
        "  )\n",
        "  lex_embd_pipeline = Pipeline([\n",
        "    ('trans', lex_ct_embed_ct),\n",
        "    ('clf', model_lex_emd_clf )\n",
        "    ]\n",
        "  )\n",
        "  emotion_pipeline = Pipeline([\n",
        "    ('trans', Emotion_ct),\n",
        "    ('clf', model_emotion_clf)\n",
        "    ]\n",
        "  )\n",
        "  \n",
        "  \n",
        "  estimators = [\n",
        "    ('sementic_estimator', sementic_pipeline),\n",
        "    ('lexP_embd_estimator', lex_embd_pipeline),\n",
        "    (\"emotion_estimator\" ,emotion_pipeline )\n",
        "  ]\n",
        "\n",
        "  final_classifier =VotingClassifier(estimators=estimators ,voting=voting) \n",
        "  final_classifier.fit(X_train, y_train)\n",
        "  write_to_pickle(outputDirectory+key+\"_\"+\"VotingClassifier_\"+voting+\".pkl\",final_classifier) \n",
        "  predicted_y= final_classifier.predict(X_val)\n",
        "  d=compute_metrics(predicted_y,y_val)\n",
        "\n",
        "  tn, fp, fn, tp = d[\"confusiton_mat\"].ravel() #correct\n",
        "  print (\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format(d['precision'][0],d['precision'][1], d['recall'][0],d['recall'][1],d['f1'][0],d['f1'][1],d['accuracy'],tn, fp, fn, tp,key,\"ExtraTree\"+voting))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7DQLKOzHC33",
        "outputId": "2327a84c-00bf-4603-8cb9-28be71be98fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prec-t\tprec-f\trec-t\trec-f\tf1-t\tf1-f\taccu\ttn\tfp\tfn\ttp\tdataset\tmodel\n",
            "0.616\t0.832\t0.936\t0.353\t0.743\t0.496\t0.659\t5224\t359\t3258\t1779\tcodalab\tcodalab\n",
            "0.510\t0.437\t0.683\t0.273\t0.584\t0.336\t0.489\t3815\t1768\t3664\t1373\tcodalab\tfakenewsnet\n",
            "0.589\t0.484\t0.146\t0.887\t0.234\t0.626\t0.497\t815\t4768\t569\t4468\tcodalab\tisot\n",
            "0.548\t0.483\t0.293\t0.732\t0.382\t0.582\t0.502\t1637\t3946\t1348\t3689\tcodalab\tkagglerealfake\n",
            "0.589\t0.583\t0.709\t0.452\t0.643\t0.509\t0.587\t3956\t1627\t2760\t2277\tcodalab\tliar\n",
            "0.787\t0.305\t0.688\t0.425\t0.734\t0.355\t0.623\t11285\t5129\t3047\t2254\tfakenewsnet\tcodalab\n",
            "0.764\t0.561\t0.985\t0.059\t0.861\t0.106\t0.759\t16171\t243\t4990\t311\tfakenewsnet\tfakenewsnet\n",
            "0.749\t0.244\t0.050\t0.948\t0.094\t0.388\t0.269\t820\t15594\t275\t5026\tfakenewsnet\tisot\n",
            "0.770\t0.246\t0.114\t0.895\t0.198\t0.386\t0.305\t1869\t14545\t557\t4744\tfakenewsnet\tkagglerealfake\n",
            "0.803\t0.304\t0.595\t0.550\t0.683\t0.392\t0.584\t9760\t6654\t2388\t2913\tfakenewsnet\tliar\n",
            "0.505\t0.744\t0.957\t0.117\t0.661\t0.201\t0.525\t20505\t911\t20076\t2648\tisot\tcodalab\n",
            "0.680\t0.966\t0.979\t0.567\t0.803\t0.714\t0.767\t20958\t458\t9840\t12884\tisot\tfakenewsnet\n",
            "0.828\t0.987\t0.989\t0.807\t0.901\t0.888\t0.895\t21172\t244\t4384\t18340\tisot\tisot\n",
            "0.786\t0.994\t0.995\t0.744\t0.878\t0.851\t0.866\t21315\t101\t5812\t16912\tisot\tkagglerealfake\n",
            "0.716\t0.812\t0.831\t0.690\t0.769\t0.746\t0.758\t17790\t3626\t7047\t15677\tisot\tliar\n",
            "0.502\t0.474\t0.905\t0.086\t0.646\t0.146\t0.499\t2871\t300\t2853\t270\tkagglerealfake\tcodalab\n",
            "0.582\t0.790\t0.913\t0.333\t0.711\t0.469\t0.625\t2895\t276\t2083\t1040\tkagglerealfake\tfakenewsnet\n",
            "0.728\t0.784\t0.812\t0.691\t0.768\t0.735\t0.752\t2575\t596\t964\t2159\tkagglerealfake\tisot\n",
            "0.714\t0.973\t0.984\t0.601\t0.828\t0.743\t0.794\t3119\t52\t1247\t1876\tkagglerealfake\tkagglerealfake\n",
            "0.612\t0.849\t0.930\t0.400\t0.738\t0.544\t0.667\t2949\t222\t1873\t1250\tkagglerealfake\tliar\n",
            "0.568\t0.479\t0.820\t0.210\t0.671\t0.292\t0.550\t5820\t1280\t4433\t1176\tliar\tcodalab\n",
            "0.559\t0.533\t0.999\t0.001\t0.717\t0.003\t0.559\t7093\t7\t5601\t8\tliar\tfakenewsnet\n",
            "0.574\t0.447\t0.272\t0.744\t0.369\t0.558\t0.480\t1932\t5168\t1435\t4174\tliar\tisot\n",
            "0.570\t0.477\t0.772\t0.263\t0.656\t0.339\t0.547\t5482\t1618\t4135\t1474\tliar\tkagglerealfake\n",
            "0.570\t0.558\t0.930\t0.112\t0.707\t0.186\t0.569\t6604\t496\t4983\t626\tliar\tliar\n"
          ]
        }
      ],
      "source": [
        "models={}\n",
        "baseModelPath= outputDirectory\n",
        "\n",
        "trained_models_path={\n",
        "  \"codalab\":baseModelPath+\"codalab\",\n",
        "  \"fakenewsnet\": baseModelPath+\"fakenewsnet\",\n",
        "  \"isot\": baseModelPath+\"isot\",\n",
        "  \"kagglerealfake\": baseModelPath+\"kagglerealfake\",\n",
        "  \"liar\":baseModelPath+\"liar\",\n",
        "}\n",
        " \n",
        "print(\"{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format('prec-t','prec-f', 'rec-t','rec-f','f1-t','f1-f','accu','tn', 'fp', 'fn', 'tp',\"dataset\",\"model\"))  # correct\n",
        "\n",
        "for key1,value1 in all_df.items():\n",
        "  df = value1\n",
        "  X_val=df[All_features]\n",
        "  y_val=df[\"label\"]\n",
        "  for key2,value in trained_models_path.items():\n",
        "    Path =value+\"_VotingClassifier_\"+voting+ \".pkl\" \n",
        "    value2=read_pickle_model(Path)\n",
        "    predicted_y= value2.predict(X_val)\n",
        "    d=compute_metrics(predicted_y,y_val)\n",
        "\n",
        "    tn, fp, fn, tp = d[\"confusiton_mat\"].ravel() #correct\n",
        "    print (\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format(d['precision'][0],d['precision'][1], d['recall'][0],d['recall'][1],d['f1'][0],d['f1'][1],d['accuracy'],tn, fp, fn, tp,key1,key2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdYIYNb0xmbu"
      },
      "source": [
        "# Voting Classifier updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MphWnB6Fxmbu",
        "outputId": "feff5d0a-3bbc-413a-9e14-6e71f6e5e23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary\n",
            " Class 0- True news \n",
            " Class 1 - False news\n",
            "\n",
            "prec-t\tprec-f\trec-t\trec-f\tf1-t\tf1-f\taccu\ttn\tfp\tfn\ttp\tdataset\tmodel\n",
            "0.816\t0.851\t0.876\t0.781\t0.845\t0.814\t0.831\t1955\t277\t442\t1576\tcodalab\tExtraTreehard\n",
            "0.771\t0.693\t0.986\t0.095\t0.866\t0.167\t0.769\t4858\t67\t1439\t151\tfakenewsnet\tExtraTreehard\n",
            "0.999\t1.000\t1.000\t0.999\t0.999\t0.999\t0.999\t6422\t3\t4\t6813\tisot\tExtraTreehard\n",
            "0.988\t0.981\t0.981\t0.988\t0.985\t0.985\t0.985\t934\t18\t11\t926\tkagglerealfake\tExtraTreehard\n",
            "0.576\t0.572\t0.823\t0.281\t0.678\t0.377\t0.575\t1134\t244\t834\t326\tliar\tExtraTreehard\n"
          ]
        }
      ],
      "source": [
        "# Train using all the features | Voting claasifier \n",
        "n_estimators=300\n",
        "voting=\"hard\"\n",
        "print(\"Summary\\n Class 0- True news \\n Class 1 - False news\\n\")\n",
        "print(\"{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format('prec-t','prec-f', 'rec-t','rec-f','f1-t','f1-f','accu','tn', 'fp', 'fn', 'tp',\"dataset\",\"model\"))  # correct\n",
        "\n",
        "for key,value in all_df.items():\n",
        "  # print(\"----------\",key,\"--------------\")\n",
        "  df = value\n",
        "  if (key==\"codalab\" or key==\"liar\"):\n",
        "    df_train = df.loc[df[\"split_Sementic\"]==\"train\"][All_features+['label']]\n",
        "    df_test = df.loc[df[\"split_Sementic\"]!=\"train\"][All_features+['label']]  \n",
        "\n",
        "    X_train=df_train[All_features]\n",
        "    y_train=df_train[\"label\"]\n",
        "    X_val=df_test[All_features]\n",
        "    y_val=df_test[\"label\"]\n",
        "  else:\n",
        "    X_train, X_val, y_train, y_val = train_test_split(df[All_features], df[\"label\"], test_size=0.3, random_state=142,stratify=df[\"label\"])\n",
        "  \n",
        "\n",
        "\n",
        "  estimators=[\n",
        "      # ('Decision Tree Classification',DecisionTreeClassifier()),\n",
        "      # ('Gradient Boosting Classification', GradientBoostingClassifier()),\n",
        "      ('Ada Boosting Classification',AdaBoostClassifier()),\n",
        "      ('Extra Tree Classification', ExtraTreesClassifier(n_estimators=300)),\n",
        "      ('Support Vector Classification',SVC(probability=True)),\n",
        "      ('Gaussian Naive Bayes',GaussianNB()),\n",
        "      (\"xgBoost\",xgb.XGBClassifier()),\n",
        "      # (\"extra tree\",ExtraTreesClassifier()),\n",
        "      # (\"RandomForestClassifier\",RandomForestClassifier())\n",
        "  ]\n",
        "  \n",
        "  # estimators = [\n",
        "  #   ('sementic_estimator', sementic_pipeline),\n",
        "  #   ('lexP_embd_estimator', lex_embd_pipeline),\n",
        "  #   (\"emotion_estimator\" ,emotion_pipeline )\n",
        "  # ]\n",
        "\n",
        "  final_classifier =VotingClassifier(estimators=estimators ,voting=voting) \n",
        "  final_classifier.fit(X_train, y_train)\n",
        "  write_to_pickle(outputDirectory+key+\"_\"+\"VotingClassifier_\"+voting+\".pkl\",final_classifier) \n",
        "  predicted_y= final_classifier.predict(X_val)\n",
        "  d=compute_metrics(predicted_y,y_val)\n",
        "\n",
        "  tn, fp, fn, tp = d[\"confusiton_mat\"].ravel() #correct\n",
        "  print (\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format(d['precision'][0],d['precision'][1], d['recall'][0],d['recall'][1],d['f1'][0],d['f1'][1],d['accuracy'],tn, fp, fn, tp,key,\"ExtraTree\"+voting))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyC2lpWvxmbw",
        "outputId": "f16b3c8c-e7db-4887-a8ba-a32819cc159b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prec-t\tprec-f\trec-t\trec-f\tf1-t\tf1-f\taccu\ttn\tfp\tfn\ttp\tdataset\tmodel\n",
            "0.847\t0.884\t0.903\t0.820\t0.874\t0.851\t0.864\t5043\t540\t909\t4128\tcodalab\tcodalab\n",
            "0.539\t0.841\t0.989\t0.063\t0.698\t0.117\t0.550\t5523\t60\t4719\t318\tcodalab\tfakenewsnet\n",
            "0.492\t0.462\t0.252\t0.711\t0.333\t0.560\t0.470\t1408\t4175\t1454\t3583\tcodalab\tisot\n",
            "0.507\t0.463\t0.359\t0.612\t0.420\t0.527\t0.479\t2005\t3578\t1953\t3084\tcodalab\tkagglerealfake\n",
            "0.582\t0.675\t0.864\t0.313\t0.696\t0.428\t0.603\t4822\t761\t3458\t1579\tcodalab\tliar\n",
            "0.802\t0.267\t0.356\t0.728\t0.493\t0.391\t0.447\t5841\t10573\t1444\t3857\tfakenewsnet\tcodalab\n",
            "0.776\t0.786\t0.990\t0.116\t0.870\t0.203\t0.777\t16246\t168\t4684\t617\tfakenewsnet\tfakenewsnet\n",
            "0.760\t0.246\t0.260\t0.746\t0.387\t0.370\t0.379\t4264\t12150\t1344\t3957\tfakenewsnet\tisot\n",
            "0.757\t0.245\t0.361\t0.642\t0.489\t0.354\t0.430\t5926\t10488\t1900\t3401\tfakenewsnet\tkagglerealfake\n",
            "0.781\t0.319\t0.771\t0.332\t0.776\t0.325\t0.664\t12654\t3760\t3543\t1758\tfakenewsnet\tliar\n",
            "0.716\t0.620\t0.463\t0.827\t0.563\t0.709\t0.650\t9921\t11495\t3937\t18787\tisot\tcodalab\n",
            "0.564\t0.896\t0.963\t0.298\t0.711\t0.447\t0.621\t20631\t785\t15960\t6764\tisot\tfakenewsnet\n",
            "1.000\t1.000\t1.000\t1.000\t1.000\t1.000\t1.000\t21411\t5\t4\t22720\tisot\tisot\n",
            "0.999\t0.999\t0.999\t0.999\t0.999\t0.999\t0.999\t21387\t29\t30\t22694\tisot\tkagglerealfake\n",
            "0.547\t0.662\t0.792\t0.383\t0.647\t0.485\t0.581\t16964\t4452\t14023\t8701\tisot\tliar\n",
            "0.558\t0.515\t0.282\t0.774\t0.375\t0.618\t0.526\t894\t2277\t707\t2416\tkagglerealfake\tcodalab\n",
            "0.512\t0.519\t0.743\t0.282\t0.607\t0.365\t0.514\t2357\t814\t2243\t880\tkagglerealfake\tfakenewsnet\n",
            "0.994\t0.961\t0.961\t0.994\t0.977\t0.977\t0.977\t3046\t125\t19\t3104\tkagglerealfake\tisot\n",
            "0.993\t0.989\t0.989\t0.993\t0.991\t0.991\t0.991\t3136\t35\t23\t3100\tkagglerealfake\tkagglerealfake\n",
            "0.588\t0.748\t0.874\t0.378\t0.703\t0.502\t0.628\t2773\t398\t1944\t1179\tkagglerealfake\tliar\n",
            "0.608\t0.467\t0.371\t0.697\t0.461\t0.559\t0.515\t2637\t4463\t1697\t3912\tliar\tcodalab\n",
            "0.559\t0.483\t0.996\t0.005\t0.716\t0.010\t0.559\t7069\t31\t5580\t29\tliar\tfakenewsnet\n",
            "0.562\t0.444\t0.499\t0.508\t0.528\t0.474\t0.503\t3540\t3560\t2761\t2848\tliar\tisot\n",
            "0.569\t0.456\t0.599\t0.425\t0.584\t0.440\t0.522\t4255\t2845\t3226\t2383\tliar\tkagglerealfake\n",
            "0.640\t0.713\t0.881\t0.374\t0.742\t0.490\t0.657\t6255\t845\t3513\t2096\tliar\tliar\n"
          ]
        }
      ],
      "source": [
        "models={}\n",
        "baseModelPath= outputDirectory\n",
        "\n",
        "trained_models_path={\n",
        "  \"codalab\":baseModelPath+\"codalab\",\n",
        "  \"fakenewsnet\": baseModelPath+\"fakenewsnet\",\n",
        "  \"isot\": baseModelPath+\"isot\",\n",
        "  \"kagglerealfake\": baseModelPath+\"kagglerealfake\",\n",
        "  \"liar\":baseModelPath+\"liar\",\n",
        "}\n",
        " \n",
        "print(\"{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format('prec-t','prec-f', 'rec-t','rec-f','f1-t','f1-f','accu','tn', 'fp', 'fn', 'tp',\"dataset\",\"model\"))  # correct\n",
        "\n",
        "for key1,value1 in all_df.items():\n",
        "  df = value1\n",
        "  X_val=df[All_features]\n",
        "  y_val=df[\"label\"]\n",
        "  for key2,value in trained_models_path.items():\n",
        "    Path =value+\"_VotingClassifier_\"+voting+ \".pkl\" \n",
        "    value2=read_pickle_model(Path)\n",
        "    predicted_y= value2.predict(X_val)\n",
        "    d=compute_metrics(predicted_y,y_val)\n",
        "\n",
        "    tn, fp, fn, tp = d[\"confusiton_mat\"].ravel() #correct\n",
        "    print (\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\\t{:}\".format(d['precision'][0],d['precision'][1], d['recall'][0],d['recall'][1],d['f1'][0],d['f1'][1],d['accuracy'],tn, fp, fn, tp,key1,key2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Model_and_Cross_Validate_single_pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
